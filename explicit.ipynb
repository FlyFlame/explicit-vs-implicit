{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explicit vs implicit feedback models\n",
    "\n",
    "This short notebook is meant to illustrate the importance of modelling implicit feedback in recommender systems. It reproduces the results of Harald Steck's [seminal paper](https://pdfs.semanticscholar.org/b7a6/4986251bfcf5fa3cac4e0c67ab2b2e78a082.pdf), _Training and Testing of Recommender Systems on Data Missing Not at Random_.\n",
    "\n",
    "Its main thrust is this: it is _never_ appropriate the evaluate recommender system on observed ratings only, and when one evaluates a system based on constructing a ranking over all items, modelling implicit feedback is crucial.\n",
    "\n",
    "For this experiment we're going to use [Spotlight](https://github.com/maciejkula/spotlight) to:\n",
    "\n",
    "1. Fit an explicit recommender system based on observed ratings only.\n",
    "2. Fit an implicit recommender system based on what ratings were and were not observed.\n",
    "3. Compare their performance in ranking _all_ items using the [Mean Reciprocal Rank, (MRR)](https://en.wikipedia.org/wiki/Mean_reciprocal_rank) metric.\n",
    "\n",
    "Let's import Spotlight first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from spotlight.cross_validation import random_train_test_split\n",
    "from spotlight.datasets.movielens import get_movielens_dataset\n",
    "from spotlight.factorization import explicit, implicit\n",
    "from spotlight.evaluation import mrr_score, rmse_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set some hyperparameters, get the dataset and split it into test and train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42\n",
    "LATENT_DIM = 32\n",
    "NUM_EPOCHS = 10\n",
    "BATCH_SIZE = 256\n",
    "L2 = 1e-6\n",
    "LEARNING_RATE = 1e-3\n",
    "\n",
    "dataset = get_movielens_dataset('100K')\n",
    "train, test = random_train_test_split(dataset, random_state=np.random.RandomState(RANDOM_SEED))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create two models: and explicit feedback model trained to minimize the squared difference of true and predicted ratings on observed ratings only, and an implicit model whose goal is to rank all watched items over all items that weren't watched."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "explicit_model = explicit.ExplicitFactorizationModel(loss='regression',\n",
    "                                                     embedding_dim=LATENT_DIM,\n",
    "                                                     n_iter=NUM_EPOCHS,\n",
    "                                                     learning_rate=LEARNING_RATE,\n",
    "                                                     batch_size=BATCH_SIZE,\n",
    "                                                     l2=L2,\n",
    "                                                     random_state=np.random.RandomState(RANDOM_SEED))\n",
    "implicit_model = implicit.ImplicitFactorizationModel(loss='bpr',\n",
    "                                                     embedding_dim=LATENT_DIM,\n",
    "                                                     n_iter=NUM_EPOCHS,\n",
    "                                                     learning_rate=LEARNING_RATE,\n",
    "                                                     batch_size=BATCH_SIZE,\n",
    "                                                     l2=L2,\n",
    "                                                     random_state=np.random.RandomState(RANDOM_SEED))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the models (shouldn't take more than 30 seconds)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "explicit_model.fit(train)\n",
    "implicit_model.fit(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just to make sure that the explicit model is of decent quality, we compute its RMSE score on the test set. Anything below 1.0 is a reasonable model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explicit RMSE: 0.94.\n"
     ]
    }
   ],
   "source": [
    "print('Explicit RMSE: {:.2f}.'.format(rmse_score(explicit_model, test).mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How good are the two models when trying to rank all items? A perfect score would rank all seen items in the test set over all unseen items (we exclude seen items from the training set from the evaluation), and return a score of 1.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explicit MRR: 0.02\n"
     ]
    }
   ],
   "source": [
    "print('Explicit MRR: {:.2f}'.format(mrr_score(explicit_model, test, train=train).mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Implicit MRR: 0.07\n"
     ]
    }
   ],
   "source": [
    "print('Implicit MRR: {:.2f}'.format(mrr_score(implicit_model, test, train=train).mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The explicit model is _awful_: the two models are not even close. You should _never_ use pure explicit feedback models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
